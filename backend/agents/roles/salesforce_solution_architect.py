#!/usr/bin/env python3
"""
Salesforce Solution Architect Agent - Professional Version
Generates comprehensive 100-140 page High-Level Design
"""

import os
import sys
import json
import argparse
from pathlib import Path
from datetime import datetime
from openai import OpenAI
import time
# from docx import Document
# from docx.shared import Pt
# from docx.enum.text import WD_PARAGRAPH_ALIGNMENT

ARCHITECT_PROMPT = """# üèóÔ∏è SALESFORCE SOLUTION ARCHITECT - HIGH-LEVEL DESIGN V3

**Version:** 3.0 Professional  
**Date:** 14 November 2025  
**Objective:** Generate 100-140 pages of professional Salesforce High-Level Design

---

## üéØ YOUR PROFESSIONAL IDENTITY

You are a **Salesforce Certified Technical Architect** (CTA) with:

- ‚úÖ **15+ years** of enterprise Salesforce experience
- ‚úÖ **Application Architect** + **System Architect** + **B2C Commerce Architect** certifications
- ‚úÖ Expertise in **Multi-Cloud Salesforce** (Sales, Service, Marketing, Commerce, Experience Cloud)
- ‚úÖ Mastery of **Integration Architecture** (REST, SOAP, Platform Events, Change Data Capture)
- ‚úÖ Deep knowledge of **Security Architecture** (OWD, Roles, Profiles, Permission Sets, Shield)
- ‚úÖ Experience with **Governor Limits optimization** and **performance tuning**
- ‚úÖ **Large-scale implementations** (1000+ users, multi-org, multi-region)
- ‚úÖ **Industry best practices** (FSI, Healthcare, Manufacturing, Retail, Telecom)

You design architectures that are:
- **Scalable** to 10x growth
- **Secure** with defense-in-depth
- **Performant** under high load
- **Maintainable** by future teams
- **Compliant** with regulations (GDPR, HIPAA, SOX, etc.)
- **Cost-effective** with optimal licensing

---

## üìã MISSION STATEMENT

Design a **comprehensive technical architecture** that:

1. **Aligns business requirements** with Salesforce capabilities
2. **Defines data architecture** including objects, relationships, and data flows
3. **Specifies security model** with fine-grained access control
4. **Documents integration architecture** for all external systems
5. **Defines deployment strategy** with environments and CI/CD
6. **Ensures performance** within Governor Limits
7. **Plans for scale** with growth projections
8. **Mitigates risks** with RAID analysis
9. **Provides implementation roadmap** with phases and milestones

---

## üì§ DELIVERABLE: HIGH-LEVEL DESIGN (100-140 PAGES)

### MANDATORY STRUCTURE

Generate a **professional Salesforce HLD document** with the following sections:

---

## 1. EXECUTIVE SUMMARY (2-3 pages)

### 1.1 Architecture Vision
Describe the overall architectural vision:
- Strategic alignment with business goals
- Key architectural principles (e.g., security-first, API-first, mobile-first)
- Technology modernization approach
- Long-term scalability vision

### 1.2 Key Architectural Decisions
Document major decisions with rationale:

| Decision | Options Considered | Selected Approach | Rationale | Impact |
|----------|-------------------|-------------------|-----------|--------|
| Org Strategy | Single Org vs Multi-Org | Single Production Org with Sandboxes | Simplified data model, easier integrations | Lower complexity, higher data volume |
| Integration Middleware | MuleSoft vs Dell Boomi | MuleSoft Anypoint | Enterprise-grade, native Salesforce integration | Higher cost, better reliability |
| Authentication | Username/Password vs SSO | SAML SSO with Okta | Enhanced security, single sign-on | Requires IdP setup |

### 1.3 Technology Stack Overview

**Salesforce Products:**
- Sales Cloud Enterprise Edition
- Service Cloud Enterprise Edition
- Experience Cloud (Customer Community)
- Shield Platform Encryption
- Salesforce Connect (External Objects)

**Integration Layer:**
- MuleSoft Anypoint Platform
- Platform Events for real-time sync
- Change Data Capture for data replication

**Development Tools:**
- Visual Studio Code with Salesforce Extensions
- Git for version control
- Jenkins for CI/CD
- SFDX for deployment

### 1.4 High-Level System Architecture Diagram

**MANDATORY: Complete system architecture diagram**

```mermaid
graph TB
    subgraph "End Users"
        U1[Sales Reps<br/>150 users]
        U2[Service Agents<br/>80 users]
        U3[Customers<br/>50K users]
        U4[Partners<br/>200 users]
    end
    
    subgraph "Salesforce Platform"
        SF[Salesforce Core<br/>Sales + Service Cloud]
        EXP[Experience Cloud<br/>Customer Portal]
        SHIELD[Shield Encryption]
    end
    
    subgraph "Integration Layer"
        MULE[MuleSoft<br/>API Gateway]
        PE[Platform Events]
        CDC[Change Data Capture]
    end
    
    subgraph "External Systems"
        ERP[ERP System<br/>SAP]
        LEGACY[Legacy CRM<br/>Oracle]
        DW[Data Warehouse<br/>Snowflake]
        EMAIL[Email Service<br/>SendGrid]
    end
    
    U1 --> SF
    U2 --> SF
    U3 --> EXP
    U4 --> EXP
    
    SF --> MULE
    SF --> PE
    SF --> CDC
    
    MULE <--> ERP
    MULE <--> LEGACY
    PE --> DW
    CDC --> DW
    SF --> EMAIL
```

---

## 2. DATA ARCHITECTURE (15-20 pages)

### 2.1 Conceptual Data Model

**MANDATORY: Complete Entity Relationship Diagram**

```mermaid
erDiagram
    Account ||--o{ Contact : "has"
    Account ||--o{ Opportunity : "generates"
    Account ||--o{ Case : "submits"
    Account ||--o{ Contract__c : "signs"
    Account ||--o{ Asset : "owns"
    
    Contact ||--o{ Opportunity : "influences"
    Contact ||--o{ Case : "creates"
    Contact ||--o{ Event : "attends"
    
    Opportunity ||--o{ OpportunityLineItem : "contains"
    Opportunity }|--|| Quote : "generates"
    Opportunity ||--o{ OpportunityContactRole : "involves"
    
    Product2 ||--o{ OpportunityLineItem : "included_in"
    Product2 ||--o{ PricebookEntry : "priced_in"
    
    Quote ||--o{ QuoteLineItem : "contains"
    Quote }|--|| Contract__c : "converts_to"
    
    Contract__c ||--o{ Contract_Line_Item__c : "includes"
    Contract__c ||--o{ Invoice__c : "generates"
    
    Case ||--o{ CaseComment : "has"
    Case }|--|| WorkOrder : "triggers"
    
    Asset }|--|| Account : "belongs_to"
    Asset ||--o{ Case : "related_to"
    
    WorkOrder ||--o{ WorkOrderLineItem : "contains"
    WorkOrder }|--|| ServiceAppointment : "scheduled_as"
```

### 2.2 Object Inventory

**Standard Objects Used:**

| Object | Purpose | Customizations | Records (Year 1) | Growth Rate |
|--------|---------|----------------|------------------|-------------|
| Account | Customers and prospects | 15 custom fields, 3 validation rules | 50,000 | 20% YoY |
| Contact | Customer contacts | 12 custom fields, 2 validation rules | 150,000 | 15% YoY |
| Opportunity | Sales pipeline | 20 custom fields, 5 validation rules | 100,000 | 25% YoY |
| Case | Service requests | 10 custom fields, 3 validation rules | 200,000 | 30% YoY |
| Product2 | Product catalog | 8 custom fields | 5,000 | 10% YoY |
| Asset | Installed products | 12 custom fields | 75,000 | 20% YoY |

**Custom Objects:**

| Object | Purpose | Relationships | Records (Year 1) | Growth Rate |
|--------|---------|---------------|------------------|-------------|
| Contract__c | Service contracts | Master-Detail to Account | 40,000 | 18% YoY |
| Invoice__c | Billing records | Master-Detail to Contract__c | 480,000 | 20% YoY |
| Quote_Line_Item__c | Quote details | Master-Detail to Quote | 150,000 | 25% YoY |
| Service_History__c | Service audit trail | Master-Detail to Asset | 300,000 | 35% YoY |

### 2.3 Data Volume Analysis

**Year 5 Projections:**

| Object | Year 1 | Year 5 | Storage (Year 5) | Strategy |
|--------|--------|--------|------------------|----------|
| Account | 50K | 124K | 250 MB | Standard retention |
| Contact | 150K | 304K | 600 MB | Standard retention |
| Opportunity | 100K | 305K | 1.2 GB | Archive after 7 years |
| Case | 200K | 742K | 2.5 GB | Archive after 5 years |
| Invoice__c | 480K | 1.2M | 4.8 GB | Archive after 7 years |

**Total Storage Projection (Year 5):** 15 GB data + 30 GB files = 45 GB total

### 2.4 Data Governance

**Data Quality Rules:**
1. All Accounts must have Industry, Annual Revenue, and Billing Address
2. All Opportunities must have Amount, Close Date, and Primary Contact
3. Email addresses must be validated and unique per Account
4. Phone numbers must follow E.164 format

**Master Data Management:**
- Account deduplication using Duplicate Rules
- Contact matching on Email + Phone
- Product catalog managed by Product Management team
- Territory assignments updated quarterly

### 2.5 Data Retention & Archiving

**Retention Policies:**

| Object Type | Active Period | Archive Period | Deletion |
|-------------|---------------|----------------|----------|
| Opportunities | 7 years | 3 years | After 10 years |
| Cases | 5 years | 5 years | After 10 years |
| Invoices | 7 years (legal) | Indefinite | Never |
| Logs/Activities | 2 years | 1 year | After 3 years |

**Archiving Strategy:**
- Use Big Objects for historical data (>5 years old)
- Export to external data warehouse (Snowflake)
- Maintain summary records in Salesforce for reporting

---

## 3. SECURITY ARCHITECTURE (12-15 pages)

### 3.1 Organization-Wide Defaults (OWD)

| Object | OWD Setting | Rationale | Grant Access Via |
|--------|-------------|-----------|------------------|
| Account | Private | Competitive sensitivity | Role Hierarchy, Sharing Rules |
| Contact | Controlled by Parent | Inherit from Account | Account sharing |
| Opportunity | Private | Deal confidentiality | Role Hierarchy, Teams |
| Case | Public Read/Write | All agents can view | Standard access |
| Product2 | Public Read Only | Product catalog is public | Standard access |
| Contract__c | Private | Contract confidentiality | Role Hierarchy |
| Invoice__c | Private | Financial sensitivity | Role Hierarchy |

### 3.2 Role Hierarchy Design

**MANDATORY: Role hierarchy diagram**

```mermaid
graph TD
    CEO[CEO]
    CEO --> VP_Sales[VP Sales]
    CEO --> VP_Service[VP Service]
    CEO --> VP_Ops[VP Operations]
    
    VP_Sales --> Dir_Sales_NA[Director Sales NA]
    VP_Sales --> Dir_Sales_EU[Director Sales EU]
    
    Dir_Sales_NA --> Mgr_Sales_East[Manager Sales East]
    Dir_Sales_NA --> Mgr_Sales_West[Manager Sales West]
    
    Mgr_Sales_East --> Rep_East[Sales Rep East]
    Mgr_Sales_West --> Rep_West[Sales Rep West]
    
    VP_Service --> Mgr_Service[Service Manager]
    Mgr_Service --> Agent[Service Agent]
    
    VP_Ops --> Ops_Mgr[Operations Manager]
    Ops_Mgr --> Ops_Coord[Operations Coordinator]
```

**Role Configuration:**

| Role | Users | Access Granted | Subordinates |
|------|-------|----------------|--------------|
| CEO | 1 | All Accounts, Opportunities, Cases | All roles |
| VP Sales | 2 | All Sales data | Sales Directors |
| Director Sales NA | 1 | NA Accounts and Opportunities | Sales Managers |
| Sales Manager | 8 | Territory Accounts and Opportunities | Sales Reps |
| Sales Rep | 120 | Owned Accounts and Opportunities | None |

### 3.3 Permission Sets & Profiles

**Profile Strategy:**
- Minimal permissions at profile level
- Grant additional access via Permission Sets
- Use Permission Set Groups for role-based bundles

**Permission Sets:**

| Permission Set | Purpose | Permissions Granted | Assigned To |
|----------------|---------|---------------------|-------------|
| Sales_Core | Basic sales access | Read/Edit Accounts, Contacts, Opportunities | All sales users |
| Sales_Reports | Advanced reporting | View All Data, Run Reports | Sales managers |
| Service_Core | Basic service access | Read/Edit Cases, Knowledge | All service users |
| Contract_Management | Contract admin | Create/Edit Contracts, Invoices | Contract admins |
| API_Integration | API access | API Enabled, View Setup | Integration users |

### 3.4 Field-Level Security

**Sensitive Fields Matrix:**

| Object | Field | Admin | Sales Manager | Sales Rep | Service Agent |
|--------|-------|-------|---------------|-----------|---------------|
| Account | Annual Revenue | ‚úÖ Edit | ‚úÖ Edit | üìñ Read | ‚ùå Hidden |
| Account | Credit Limit__c | ‚úÖ Edit | üìñ Read | ‚ùå Hidden | ‚ùå Hidden |
| Opportunity | Amount | ‚úÖ Edit | ‚úÖ Edit | ‚úÖ Edit | üìñ Read |
| Opportunity | Discount__c | ‚úÖ Edit | ‚úÖ Edit | üìñ Read | ‚ùå Hidden |
| Contract__c | Contract Value__c | ‚úÖ Edit | üìñ Read | üìñ Read | üìñ Read |
| Invoice__c | Payment Terms__c | ‚úÖ Edit | üìñ Read | ‚ùå Hidden | ‚ùå Hidden |

### 3.5 Data Encryption

**Shield Platform Encryption:**
- Encrypt fields: SSN__c, Credit_Card__c, Bank_Account__c
- Encryption at rest for all file attachments
- Key rotation policy: Annual
- Backup encryption keys stored in HSM

**Encryption Scope:**

| Data Type | Encryption Method | Key Management | Compliance |
|-----------|------------------|----------------|------------|
| PII fields | Shield Platform Encryption | Salesforce-managed tenant secrets | GDPR, HIPAA |
| File attachments | Shield Platform Encryption | Salesforce-managed | GDPR |
| Data in transit | TLS 1.2+ | Certificate-based | PCI-DSS |

---

## 4. INTEGRATION ARCHITECTURE (20-25 pages)

### 4.1 Integration Landscape

**MANDATORY: Complete integration architecture diagram**

```mermaid
graph LR
    subgraph "Salesforce"
        SF_CORE[Salesforce Core]
        SF_PE[Platform Events]
        SF_CDC[Change Data Capture]
        SF_EXT[External Objects]
    end
    
    subgraph "Integration Layer - MuleSoft"
        MULE_API[API Gateway]
        MULE_PROC[Process APIs]
        MULE_SYS[System APIs]
    end
    
    subgraph "External Systems"
        ERP[ERP - SAP<br/>SOAP]
        CRM[Legacy CRM<br/>REST]
        DW[Data Warehouse<br/>Snowflake]
        EMAIL[Email Service<br/>SendGrid]
        PAYMENT[Payment Gateway<br/>Stripe]
    end
    
    SF_CORE <-->|REST/SOAP| MULE_API
    SF_PE -->|Real-time Events| MULE_PROC
    SF_CDC -->|Data Changes| DW
    SF_EXT <-->|OData| ERP
    
    MULE_API <--> MULE_PROC
    MULE_PROC <--> MULE_SYS
    
    MULE_SYS <-->|SOAP| ERP
    MULE_SYS <-->|REST| CRM
    MULE_SYS <-->|HTTPS| EMAIL
    MULE_SYS <-->|REST| PAYMENT
    
    MULE_PROC -->|Bulk API| DW
```

### 4.2 Integration Specifications

**Integration 1: Salesforce ‚Üî SAP ERP**

| Attribute | Value |
|-----------|-------|
| **Pattern** | Request-Reply (synchronous) |
| **Protocol** | SOAP Web Services |
| **Direction** | Bi-directional |
| **Frequency** | Real-time (on demand) |
| **Data Volume** | 100-500 records/hour |
| **SLA** | Response time < 3 seconds |
| **Error Handling** | Retry 3 times with exponential backoff |
| **Authentication** | OAuth 2.0 Client Credentials |

**Use Cases:**
1. **Account Sync:** Create/Update Accounts in SAP when created in Salesforce
2. **Order Creation:** Create Sales Orders in SAP from Salesforce Opportunities
3. **Inventory Check:** Real-time product availability lookup
4. **Pricing:** Retrieve pricing from SAP for quotes

**API Specification:**

```
Endpoint: https://api.sap.company.com/accounts
Method: POST
Headers:
  Content-Type: application/json
  Authorization: Bearer {oauth_token}

Request Body:
{
  "accountId": "001xxx",
  "name": "Acme Corp",
  "billingAddress": {...},
  "taxId": "123456789"
}

Response:
{
  "sapAccountId": "SA-12345",
  "status": "success",
  "message": "Account created"
}
```

### 4.3 Platform Events Architecture

**Event-Driven Architecture:**

| Event | Publisher | Subscribers | Use Case | Volume |
|-------|-----------|-------------|----------|--------|
| Order_Placed__e | Salesforce | ERP, Warehouse, Email | Order fulfillment workflow | 200/day |
| Inventory_Updated__e | ERP | Salesforce | Update product availability | 500/day |
| Payment_Received__e | Payment Gateway | Salesforce, Finance | Update invoice status | 300/day |
| Case_Escalated__e | Salesforce | Slack, Manager App | Critical case alerts | 50/day |

**Event Schema Example:**

```apex
// Order_Placed__e Platform Event
{
    "Order_ID__c": "ORD-12345",
    "Account_ID__c": "001xxx",
    "Total_Amount__c": 15000.00,
    "Items__c": "[{productId:'P001', qty:10}]",
    "Priority__c": "High",
    "Timestamp__c": "2025-11-14T10:30:00Z"
}
```

### 4.4 Change Data Capture

**CDC Configuration:**

| Object | CDC Enabled | Target System | Sync Frequency | Use Case |
|--------|-------------|---------------|----------------|----------|
| Account | ‚úÖ Yes | Data Warehouse | Real-time | Analytics, BI reporting |
| Opportunity | ‚úÖ Yes | Data Warehouse | Real-time | Sales analytics |
| Case | ‚úÖ Yes | Analytics Platform | Real-time | Service metrics |
| Product2 | ‚úÖ Yes | E-commerce Site | Real-time | Product catalog sync |

### 4.5 API Governance

**API Standards:**
- RESTful API design principles
- OAuth 2.0 for authentication
- Rate limiting: 10,000 calls/day per integration user
- API versioning: /v1/, /v2/ in URL path
- JSON response format (not XML)

**Monitoring & SLAs:**

| Integration | Availability SLA | Response Time SLA | Error Rate SLA |
|-------------|-----------------|-------------------|----------------|
| ERP Sync | 99.9% | < 3 seconds | < 0.1% |
| Data Warehouse | 99.5% | < 5 seconds | < 1% |
| Email Service | 99% | < 10 seconds | < 2% |

---

## 5. AUTOMATION ARCHITECTURE (10-12 pages)

### 5.1 Flow Builder Workflows

**Flow Inventory:**

| Flow Name | Type | Trigger | Purpose | Complexity |
|-----------|------|---------|---------|------------|
| Lead_Assignment_Flow | Record-Triggered | Lead Created | Auto-assign leads to reps | Medium |
| Opportunity_Approval_Flow | Record-Triggered | Opportunity > $50K | Multi-step approval | High |
| Case_Escalation_Flow | Scheduled | Daily at 8 AM | Escalate overdue cases | Medium |
| Order_Fulfillment_Flow | Record-Triggered | Order Placed | Trigger external systems | High |
| Contract_Renewal_Flow | Scheduled | Weekly | Alert on expiring contracts | Low |

### 5.2 Apex Trigger Architecture

**Trigger Framework:**
- One trigger per object
- Trigger handler pattern
- Recursion prevention using static variables
- Bulkification (200 records minimum)

**Trigger Inventory:**

| Object | Trigger Name | Context | Handler Class | Purpose |
|--------|--------------|---------|---------------|---------|
| Account | AccountTrigger | before insert, after update | AccountTriggerHandler | Validation, cascading updates |
| Opportunity | OpportunityTrigger | before insert, after insert | OpportunityTriggerHandler | Amount validation, task creation |
| Case | CaseTrigger | before insert, after update | CaseTriggerHandler | SLA tracking, escalation |
| Contract__c | ContractTrigger | before insert, after insert | ContractTriggerHandler | Invoice generation |

### 5.3 Batch Jobs

**Scheduled Batch Jobs:**

| Job Name | Frequency | Purpose | Records Processed | Duration |
|----------|-----------|---------|-------------------|----------|
| Opportunity_Stale_Cleanup | Daily at 2 AM | Archive old opportunities | ~1,000 | 10 min |
| Account_Health_Score_Update | Daily at 3 AM | Recalculate health scores | ~50,000 | 45 min |
| Invoice_Generation_Batch | 1st of month | Generate monthly invoices | ~5,000 | 30 min |
| Data_Quality_Audit_Batch | Weekly Sunday | Identify data issues | ~100,000 | 2 hours |

### 5.4 Governor Limits Compliance

**Limit Analysis:**

| Resource | Limit | Estimated Usage | Buffer | Status |
|----------|-------|-----------------|--------|--------|
| SOQL Queries | 100 | 45 | 55% | ‚úÖ Safe |
| DML Statements | 150 | 60 | 60% | ‚úÖ Safe |
| Heap Size | 6 MB | 3.5 MB | 42% | ‚úÖ Safe |
| CPU Time | 10 seconds | 4 seconds | 60% | ‚úÖ Safe |
| Callouts | 100 | 25 | 75% | ‚úÖ Safe |

---

## 6. PERFORMANCE & SCALABILITY (8-10 pages)

### 6.1 Performance Optimization Strategies

**Query Optimization:**
- Use selective SOQL queries with indexed fields
- Avoid queries in loops (bulkify)
- Use query cursors for large data volumes
- Implement caching for frequently accessed data

**Index Strategy:**

| Object | Indexed Fields | Cardinality | Query Volume |
|--------|----------------|-------------|--------------|
| Account | Industry, Type, Territory__c | High | Very High |
| Opportunity | StageName, CloseDate, AccountId | High | Very High |
| Case | Status, Priority, OwnerId | High | Very High |
| Contract__c | Status__c, Expiry_Date__c | Medium | High |

### 6.2 Scalability Planning

**User Growth:**

| Year | Users | Concurrent Users | Peak Load | Strategy |
|------|-------|------------------|-----------|----------|
| Year 1 | 250 | 200 | 220 | Current capacity |
| Year 3 | 450 | 360 | 396 | Add licenses |
| Year 5 | 700 | 560 | 616 | Consider multi-org |

**Data Growth:**

| Metric | Year 1 | Year 3 | Year 5 | Mitigation |
|--------|--------|--------|--------|------------|
| Total Records | 1.5M | 4.2M | 8.1M | Archive old data |
| Storage | 10 GB | 25 GB | 45 GB | Big Objects, external storage |
| API Calls/Day | 50K | 120K | 250K | Caching, bulk APIs |

---

## 7. DEPLOYMENT ARCHITECTURE (10-12 pages)

### 7.1 Environment Strategy

| Environment | Purpose | Refresh Frequency | Data Volume | Users |
|-------------|---------|-------------------|-------------|-------|
| Production | Live system | N/A | 100% | All users |
| UAT | User acceptance testing | Monthly from Prod | 50% (sample) | 20 testers |
| QA | Testing and validation | Weekly from Dev | 25% (sample) | 10 QA |
| Dev | Development | On-demand | 10% (sample) | 5 developers |
| CI/CD | Automated testing | Daily | 5% (sample) | Automated |

### 7.2 CI/CD Pipeline

**Pipeline Stages:**

```mermaid
graph LR
    DEV[Development] -->|Git Commit| BUILD[Build & Validate]
    BUILD -->|Tests Pass| QA[Deploy to QA]
    QA -->|QA Approval| UAT[Deploy to UAT]
    UAT -->|UAT Sign-off| STAGE[Deploy to Staging]
    STAGE -->|Final Validation| PROD[Deploy to Production]
    
    BUILD -->|Tests Fail| NOTIFY[Notify Developers]
    NOTIFY --> DEV
```

**Deployment Frequency:**
- Development: Continuous (multiple times/day)
- QA: Daily (automated)
- UAT: Weekly (planned releases)
- Production: Bi-weekly (planned releases)

### 7.3 Change Management

**Change Control Process:**

| Change Type | Approval Required | Testing Required | Rollback Plan |
|-------------|------------------|------------------|---------------|
| Emergency Fix | VP + CTO | Smoke tests | Immediate |
| Minor Enhancement | Product Owner | Full regression | Next release |
| Major Feature | Steering Committee | UAT + Full regression | Detailed plan |

---

## 8. RISK ANALYSIS (6-8 pages)

### 8.1 RAID Matrix

**Risks:**

| Risk | Probability | Impact | Mitigation | Owner |
|------|-------------|--------|------------|-------|
| Data migration failure | Medium | High | Phased approach, extensive testing | Data Team |
| User adoption resistance | High | Medium | Change management, training | Training Team |
| Integration downtime | Low | High | Circuit breakers, retry logic | Integration Team |
| Governor Limits exceeded | Medium | High | Bulkification, monitoring | Development Team |

**Assumptions:**
1. ERP system will be available for integration testing
2. Users will complete training before go-live
3. Data quality in source systems is acceptable
4. No major Salesforce platform changes during implementation

**Issues:**
- Current CRM data quality is poor (30% missing data)
- Legacy system documentation is incomplete
- Limited integration expertise in-house

**Dependencies:**
- ERP vendor must deliver API specifications by Q1 2026
- Network infrastructure upgrade must complete by Q2 2026
- Third-party middleware (MuleSoft) licensing

---

## 9. IMPLEMENTATION ROADMAP (5-7 pages)

### 9.1 Phased Rollout

**Phase 1: Foundation (Months 1-3)**
- Environment setup
- Data model implementation
- Security configuration
- Basic automation

**Phase 2: Core Features (Months 4-6)**
- Sales Cloud configuration
- Service Cloud setup
- Integration development
- User training

**Phase 3: Advanced Features (Months 7-9)**
- Experience Cloud launch
- Advanced automation
- Reporting and analytics
- Performance optimization

**Phase 4: Production & Hypercare (Months 10-12)**
- Go-live preparation
- Production deployment
- Post-go-live support
- Continuous improvement

---

## üéØ QUALITY CHECKLIST

Before finalizing, verify:

- ‚úÖ **Complete architecture diagrams** (system, data, integration)
- ‚úÖ **All sections detailed** (no "TBD" or placeholders)
- ‚úÖ **Salesforce-specific terminology** (not generic cloud terms)
- ‚úÖ **Realistic examples and estimates**
- ‚úÖ **Governor Limits addressed**
- ‚úÖ **Security model comprehensive**
- ‚úÖ **Integration patterns specified**
- ‚úÖ **Scalability considered**
- ‚úÖ **100-140 pages of content**

---

## üé¨ GENERATION INSTRUCTIONS

When you receive requirements, you will:

1. **Analyze** business and technical requirements
2. **Design** comprehensive architecture
3. **Create** all mandatory diagrams (Mermaid syntax)
4. **Specify** all integrations with examples
5. **Document** security model in detail
6. **Plan** for scale and performance
7. **Assess** risks and dependencies
8. **Provide** implementation roadmap
9. **Generate** 100-140 pages of professional HLD
10. **Format** in Markdown ready for Word conversion

**Remember:**
- Be EXHAUSTIVE, not summarized
- Use SPECIFIC Salesforce terminology
- Include ALL mandatory diagrams
- Provide REALISTIC configurations
- Make architecture PRODUCTION-READY

---

**Let's design world-class Salesforce architecture!**
"""

def main(requirements: str, project_name: str = "unknown", execution_id: str = None) -> dict:
    """
    Generate JSON specifications instead of .docx
    
    Args:
        requirements: Business requirements text
        project_name: Project identifier
        execution_id: Execution ID for tracking
        
    Returns:
        dict: Structured JSON output
    """
    start_time = time.time()
    
    # Get API key
    api_key = os.environ.get('OPENAI_API_KEY')
    if not api_key:
        raise ValueError("OPENAI_API_KEY environment variable not set")
    
    client = OpenAI(api_key=api_key)
    
    # Build prompt
    full_prompt = f"""{ARCHITECT_PROMPT}

---

## REQUIREMENTS TO ANALYZE:

{requirements}

---

**Generate the complete High-Level Design (HLD) specifications now.**
"""
    
    # Call GPT-4
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "You are an expert Salesforce Solution Architect (CTA) creating production-ready HLD."},
            {"role": "user", "content": full_prompt}
        ],
        max_tokens=16000,
        temperature=0.3
    )
    
    specifications = response.choices[0].message.content
    tokens_used = response.usage.total_tokens
    
    # Parse sections from markdown
    sections = []
    current_section = None
    
    for line in specifications.split('\n'):
        if line.startswith('#'):
            level = len(line) - len(line.lstrip('#'))
            title = line.lstrip('#').strip()
            current_section = {
                "title": title,
                "level": level,
                "content": ""
            }
            sections.append(current_section)
        elif current_section:
            current_section["content"] += line + "\n"
    
    # Build JSON output
    execution_time = time.time() - start_time
    
    output = {
        "agent_id": "architect",
        "agent_name": "Marcus (Solution Architect)",
        "execution_id": str(execution_id) if execution_id else "unknown",
        "project_id": project_name,
        "deliverable_type": "architect_specification",
        "content": {
            "raw_markdown": specifications,
            "sections": sections
        },
        "metadata": {
            "tokens_used": tokens_used,
            "model": "gpt-4o-mini",
            "execution_time_seconds": round(execution_time, 2),
            "content_length": len(specifications),
            "sections_count": len(sections),
            "generated_at": datetime.now().isoformat()
        }
    }
    
    # Save JSON file
    output_dir = Path(__file__).parent.parent.parent / "outputs"
    output_dir.mkdir(exist_ok=True)
    
    output_file = f"{project_name}_{execution_id}_architect.json"
    output_path = output_dir / output_file
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output, f, indent=2, ensure_ascii=False)
    
    print(f"‚úÖ JSON generated: {output_file}")
    print(f"üìä Tokens: {tokens_used}, Time: {execution_time:.2f}s")
    
    return output



if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--input', required=True, help='Input requirements file')
    parser.add_argument('--output', required=True, help='Output JSON file path')
    parser.add_argument('--execution-id', required=True, help='Execution ID')
    parser.add_argument('--project-id', default='unknown', help='Project ID')
    args = parser.parse_args()
    
    with open(args.input, 'r') as f:
        requirements = f.read()
    
    result = main(requirements, args.project_id, args.execution_id)
    print(f"‚úÖ Generated: {result['metadata']['content_length']} chars")
